---
title: "On Open Source Knowledge (DRAFT)"
description: "Why knowledge should be shared like code—structured, evergreen, and free."
---

*I am actively drafting / writing / researching this article. As such, you'll see random notes throughout.*

**TODO:** Build in public → Think in public.

## The Problem

Too much knowledge is locked away.

It's in books. It's behind paywalls. In heads that never write it down. In social media posts that vanish into timelines.

Even when it's written down in a blog post, it's buried under 1,000 words of fluff and SEO filler.

This didn't happen by accident. It's the result of how knowledge sharing evolved—and the incentives that shaped each era.

**Pre-internet**, knowledge lived in books, institutions, and heads. Sharing required publishers, gatekeepers, money. The barrier to entry was high. Most expertise never made it out.

**The early web** promised democratized publishing. Anyone could share. But there was no business model, so only hobbyists and idealists participated at scale.

**The ad-revenue era** solved the business model problem—but created new ones. When revenue comes from attention, you optimize for eyeballs, not knowledge transfer. SEO gaming, clickbait, filler content. The web got cluttered. The signal got buried and lost.

**The platform era** made publishing even easier through social media and newsletters — but ephemeral. Feeds, not archives. Engagement algorithms, not organization. Good insights vanish into timelines.

**Wikipedia** tried to solve the organization problem through centralization. It worked, to a point—but created gatekeeping, bias concerns, and a single point of editorial control. More on this later.

**Now, the AI era**: LLMs are being trained on all of the above. The noise. The SEO filler. The biased centralized sources. The ephemeral social posts. Whatever the crawlers can reach. **TODO:** Confirm the accuracy of this statement.

This is shaping what AI "knows"—and by extension, what it teaches back to us. (*Meh. This sentence needs work.*)

The knowledge that's out there is incomplete. Biased. Disproportionately shaped by a tiny fraction of people who publish. The contractor worker who's mastered their trade? Not publishing. The nurse with 30 years of experience? Not publishing. The home cook who actually knows what they're doing? Buried under recipe blogs optimized for ad impressions, not knowledge transfer.

We have a knowledge problem—one that's been building for decades. And I think open source software points to the solution.

## What Open Source Got Right

Developers figured something out decades ago: if you make your code freely available, good things happen.

Others can learn from it. They can improve it. They can adapt it to their needs. The knowledge embedded in that code—the patterns, the solutions, the hard-won lessons—spreads. It compounds. The whole ecosystem gets better.

Open source isn't just about free access. It's about:

**Portability**: The code lives in formats you control (text files, Git repositories). You're not locked into a platform.

**Version control**: You can see what changed, when, and why. History is preserved.

**Living documentation**: Updates ship as features. Content stays current.

**Community improvement**: Others can contribute, challenge, correct, and extend.

This model has built operating systems, programming languages, and much of the infrastructure that powers the internet. It works.

The question is: why haven't we applied this to knowledge more broadly?

## The Ad-Revenue Problem

The ad-driven era deserves a closer look, because its effects are still with us.

When revenue comes from time-on-page and ad impressions, you're incentivized to keep eyeballs, not to efficiently transfer what you know.

You know what this looks like. The recipe blog that makes you scroll through a 1,200-word story about someone's grandmother before you get to the ingredients. The listicle padded to hit a word count. The clickbait headline that promises more than the article delivers.

This isn't malice. It's economics. The SEO arms race made it worse—to rank, you needed word count and keyword density. Even people with genuinely useful knowledge had to play the game or get buried in search results.

The result: the web got cluttered with noise optimized for algorithms, not humans. And that noise is what's getting fed to LLMs.

**NOTE:** *This problem started before the internet. To get your ideas out there, you had to get published in books, newspapers, magazines. The era of gatekeeping. Need to add this in. And even for those who self-published and filed an ISBN – that information is locked away in physical books and libraries – much has yet to be digitized. Need to talk about this.*

## A Different Model

Open source software largely solved the monetization problem differently.

Give away the code. Build reputation. Let value accrue through other channels: consulting, services, sponsorships, jobs, speaking, books (that where physical manifestations of already free information), courses. ~~The free knowledge is the loss leader that demonstrates expertise and builds trust.~~ The free knowledge is what gets you noticed—it demonstrates expertise and builds trust, which is what leads to paid opportunities.

**TODO:** Find specific examples of OSS projects/maintainers who've made this work. Linux Foundation funding model? Specific developers who've built careers this way?

This isn't "I hope money finds me." It's a deliberate trade: short-term monetization (ads, paywalls) for long-term reputation and opportunity. It requires patience. It requires faith that valuable contributions get recognized. But it's a proven model.

I'm not prescribing this for everyone. People need to eat. Some creators genuinely need ad revenue or paywalls to sustain their work. But I do think the *primary goal* should be knowledge transfer, with monetization as secondary.

Think of it as a form of volunteering to improve your community. Sharing knowledge with the goal of making others' lives better is a version of giving back. More people should consider viewing it through this lens.

The flip side: if you consume free knowledge that's valuable to you, consider supporting it by voting with your dollars. This ensures those who may be donating elsewhere or not in a position to to still have access to the information.

*I think I want to change this section to focus more on giving back and contributing thatn monetization. So invert the argument. This is way to help you think, share knowledge with others, and, yes, there are options for monetization that go beyond ads should you desire that approach – we've gotten away from 'sponsoring' people and their work. Imagine if we all just contributed to active creators. Not a winner takes all mentality but a spread the wealth mentality.*

## Why Documentation Format Matters

Here's where I want to push beyond the standard "information wants to be free" argument.

It's not just about making knowledge available. It's about *how* it's structured and presented.

Books—physical and digital—have been the default for centuries. They're linear. Self-contained. Designed to be read cover-to-cover or referenced via the table of content or index. They work. I keep reference books on my shelf: the Annals of America, Audubon field guides, Martha Stewart's Homekeeping Handbook, The Great Mental Models. I love these books.

But books have limitations as a *primary* medium for sharing knowledge:

**Static**: Once published, they don't update easily. Errata and new editions are slow.

**Monolithic**: You often can't access just the piece you need without buying/borrowing the whole thing.

**Not machine-readable**: LLMs can't easily parse and learn from them. This affects training data and the ability to use them as context in your own learning pursuits.

**Access barriers**: Cost, availability, format restrictions.

Social media and blogs have different problems:

**Ephemeral**: Posts vanish into timelines. Good information gets lost unless you actively save it.

**Unstructured**: No consistent organization. Hard to build cumulative knowledge.

**Platform-dependent**: You don't control the format or the distribution.

**TODO:** Mention Substack specifically? It's better than X for evergreen content but still falls into the "stream" problem—posts get buried in inboxes.

Technical documentation for software has evolved a different approach. And I think it's underrated as a model for knowledge sharing generally.

Think about good software docs:

**Modular**: Individual articles that stand alone yet connect to a whole.

**Navigable**: Sidebar navigation, search, clear hierarchy. Jump to what you need.

**Evergreen**: Updated as the software evolves. Version-controlled.

**Context-preserving**: Each piece maintains its relationship to the broader system.

**Machine-readable**: Structured formats that crawlers and LLMs can parse.

*Blah. This whole section needs work. I don't like how it's reading. Plus, all reference books such as encyclopedias are inherinetly modular they just take up a lot of space and can't be easily annotated and linked to other things. Links are better for, well linking. I don't want to snap a photo of a page. I want to link it in and be able to copy the text as context for a LLM or for my own notes. Digital files are just better to manipulate especially when it comes to curating knowledge for your own extended mind system.*

This is how I think reference knowledge should be shared. Not just software documentation—*all* reference knowledge. How to maintain a home. How to evaluate a construction project. What a nurse knows about patient patterns. What a political organizer has learned about mobilization.

It's like publishing a reference book or course, but in a format better suited to how people actually access information now—and how machines are learning to access it.

## The Hayek Connection

**TODO:** Expand this section. Research Hayek's "The Use of Knowledge in Society" (1945) for direct quotes and precise framing.

The economist Friedrich Hayek made an argument in 1945 that's relevant here.

He pointed out that centralized planners can never have access to all the knowledge that matters. The most valuable knowledge is often *local* and *tacit*—held by the "man on the spot" who understands their particular circumstances in ways that can't easily be aggregated or transmitted.

The construction foreman who knows which suppliers are reliable. The ER nurse who can read a patient's condition before the tests come back. The farmer who knows their specific land. This knowledge exists. It's valuable. And it's vastly underrepresented in what's publicly available online.

**If we want LLMs—and humans—to have access to the full breadth of useful knowledge, we need more people documenting what they know.** Especially the people whose knowledge isn't currently being published.

Open source knowledge is a decentralized solution to a Hayekian information problem.

## The Wikipedia Lesson

Wikipedia was a major attempt to apply open source principles to knowledge at scale. Hayek's "The Use of Knowledge in Society" was reportedly influential in its creation—the idea that distributed contributors could collectively build something no central authority could.

Development and management of Wikipedia

*Wales at the tenth-anniversary celebration of the Bengali Wikipedia*

*Wales has cited Austrian School economist Friedrich Hayek's essay, "The Use of Knowledge in Society", which he read as an undergraduate, as "central" to his thinking about "how to manage the Wikipedia project". Hayek argued that information is decentralized—that each individual only knows a small fraction of what is known collectively—and that as a result, decisions are best made by those with local knowledge, rather than by a central authority. Wales reconsidered Hayek's essay in the 1990s while reading about the open source movement, which advocated for the collective development and free distribution of software. He was particularly moved by "The Cathedral and the Bazaar", an essay which was later adapted into a book of the same name, by one of the founders of the movement, Eric S. Raymond, as it "opened [his] eyes to the possibilities of mass collaboration."*

*From his background in finance, and working as a futures and options trader, Wales developed an interest in game theory and the effect of incentives on human collaborative activity. He identifies this fascination as a significant basis for his developmental work on the Wikipedia project. He has rejected the notion that his role in promoting Wikipedia is altruistic, which he defines as "sacrificing your own values for others", and he states that the idea that "participating in a benevolent effort to share information is somehow destroying your own values makes no sense to me".*

https://en.wikipedia.org/wiki/Jimmy_Wales

And it worked, to a point. Wikipedia became the default reference for encyclopedic knowledge. It's one of the most-visited sites on the internet. It's a primary source for LLM training data.*

But Wikipedia is centralized in a way that open source code isn't.

There's one Wikipedia. One editorial process. Notability requirements that exclude certain types of knowledge. "Neutral point of view" policies that require consensus—which means contested topics get shaped by whoever has the time and motivation to engage in edit wars.

Recent concerns have surfaced about this model:

**TODO:** Research and cite specific recent controversies about Wikipedia editing, bias, and gatekeeping. What's happened in the last few months?

- Who gets to contribute and whose edits stick
- How "neutrality" gets defined and enforced
- Systemic biases in coverage and framing
- The demographics of active editors vs. the world's population

This isn't to dismiss Wikipedia. It's an incredible achievement. But it illustrates the limits of **centralized** open knowledge.

The model I'm advocating for is different: **distributed** knowledge bases. Many individuals and small groups publishing their own documentation. No single editorial authority. No notability gatekeepers.

This is actually more faithful to how open source software works. There's no single authoritative Linux—there are distributions, forks, variations. Trust is distributed across the ecosystem. Different projects serve different needs. The "best" answer depends on context.

The tradeoff is real: distributed publishing puts the burden on the reader to evaluate sources. There's no Wikipedia stamp of "this is the neutral truth." You have to assess credibility yourself.

But I'd argue that's more honest than a centralized source that *appears* authoritative while carrying hidden biases. At least with distributed sources, the reader knows they're responsible for judgment.

And if enough people publish—especially people whose knowledge isn't currently represented—the truth emerges from the ecosystem rather than being declared by a single authority. More signal, from more sources, means better collective knowledge. For humans and machines alike.

## The AI Writing Question

A barrier to this has always been time and skill. Writing is hard. Organizing knowledge is hard. Having valuable expertise does not always equate to possessing writing as a skill.

AI changes this equation.

**TODO:** Be more specific about the workflow. Voice dictation → transcription → AI summarization/organization → human review → publication. Reference the workflow from Knowledge Bank article?

Voice dictation lets you brain-dump what you know. AI can summarize, identify gaps, organize, and draft. You review, refine, edit, and publish. The bottleneck of "I know this but I can't articulate it well or (most often the case) concisely" is dramatically reduced.

I know some people turn their noses up at AI-assisted writing. And for certain types of writing—persuasion, storytelling, creative expression—I understand the hesitation. Those are craft domains where the *process* of writing is part of the value. *Do I really think this though? Or could AI also be leveraged in the same way here? Hmmmm. Need to noodle on it.*

But knowledge transfer is different. The goal is simple: get what's in your head into a format others can learn from. This is technical writing, not creative writing. If AI helps more people capture and share what they know, especially knowledge that isn't otherwise available, that's a good thing.

The end goal is knowledge transfer. AI writing is a legitimate tool for this.

**TODO:** Consider addressing the "but AI hallucinates" objection. The human review step is critical. AI drafts, human verifies.

## What This Looks Like in Practice

I'm eating my own dogfood here.

My Extended Mind System—a methodology for personal knowledge management I've developed over years—could have been a book. An ebook. A PDF. A course.

Instead, I'm publishing it as open documentation using [Mintlify](https://mintlify.com).

Why Mintlify specifically:

**Built for humans and machines**: Designed as a knowledge base that both can read. This was the deciding factor.

**Documentation-as-code**: Markdown files, Git versioning, GitHub hosting. I control the source.

**Living documentation**: I ship updates as I refine the system. Content stays current.

**Ideal layout**: Left sidebar navigation, article in center, table of contents on right. The format I'm arguing for.

I'm releasing the system incrementally, use case by use case. Each piece stands alone while fitting into the broader framework. Progressive sharing rather than waiting until it's "done."

This approach lets people engage with the methodology through AI—asking Claude questions about it, adapting it to their needs—in ways a static PDF never could.

*The plan was to originally release as a free PDF and all my notes are currently in Scrivener. But I pivoted to Mintlify. Otherwise it may well have been at least a year before I shipped anything.*

## The Stakes

This matters more now than it did five years ago.

LLMs are being trained on what's publicly available. What's out there shapes what AI "knows." And what AI knows gets fed back to millions of people asking questions every day.

If the training data is dominated by Wikipedia (with its centralization and biases), Reddit (unstructured, ephemeral, skewed toward certain demographics), and SEO-optimized content (noise dressed as signal), that's what AI will reflect.

*We're basically feeding AI junk food right now – which is not an appropriate diet for anyone let alone LLMs in their infancy.*

**TODO:** Find research on LLM training data composition. What percentage is Wikipedia? Reddit? Common Crawl breakdown? Anthropic publications on training data?

We can complain about this. Or we can do something about it.

Every person who documents their knowledge in a structured, publicly accessible format is contributing to a better information ecosystem. You're not just helping the humans who read your work directly. You're helping shape what AI knows—and by extension, what it teaches everyone else.

## A Call to Action

If you have knowledge worth sharing—and you almost certainly do—consider this approach:

1. **Document what you know**. Use AI to help if writing isn't your strength. Voice-dictate, let AI organize, then review and refine.

2. **Structure it for access**. Modular articles. Clear navigation. Evergreen format. Think documentation, not blog posts.

3. **Make it freely available**. Open source philosophy. Let the value accrue through reputation and opportunity, not paywalls.

4. **Keep it alive**. Update as you learn more. Ship improvements. Version control your knowledge.

This is volunteering for the information age. Contributing to the commons. Making the world slightly better by sharing what you know.

And if you benefit from others doing this? Support them. Donate. Contribute. Spread the word. The ecosystem only works if value flows back to the people creating it.

---

## Further Reading and Resources

### On Open Source Philosophy and Knowledge Sharing

| Title | Description | Link |
| ----- | ----------- | ---- |
| "The Cathedral and the Bazaar" by Eric S. Raymond | The foundational text on open source development philosophy | [catb.org](http://www.catb.org/~esr/writings/cathedral-bazaar/) |
| Creative Commons | The licensing framework that enables open knowledge sharing | [creativecommons.org](https://creativecommons.org/) |
| Gwern Branwen's website | A practitioner of long-form, versioned, evergreen knowledge sharing | [gwern.net](https://gwern.net/) |

<iframe
  src="https://platform.twitter.com/embed/Tweet.html?id=1856804313227465114"
  width="550"
  height="600"
  style={{ border: "none", overflow: "hidden" }}
/>

*Gwern has built exactly what I am advocating for. And it's a beautiful site. Need to note how I stumbled upon him in my research for this article and how I got lost in his site. And this is another benefit of posting online. Especially for introverts – you're apt to find like-minded people you may not have encountered otherwise. Especially important for people with niche thinking styles and younger individuals who could benefit from the perspective earlier in life..*

### On the Knowledge Problem and Tacit Knowledge

**"The Use of Knowledge in Society" by Friedrich Hayek (1945)**

The original articulation of the "man on the spot" argument. [Available via various academic sources]

**"Personal Knowledge" by Michael Polanyi**

Deep exploration of tacit knowledge and how it's transmitted.

**TODO:** Add more sources on tacit knowledge, especially practical/applied works

### On LLM Training Data and Bias

**TODO:** List specific academic papers or training data composition and bias.

- [Placeholder for research on Wikipedia's influence on LLM training]
- [Placeholder for research on Reddit's influence on LLM training]
- [Placeholder for Common Crawl analysis]


**Common Corpus: The Largest Collection of Ethical Data for LLM Pre-Training (2025)**

Documents the "open data paradox": most freely licensed content isn't integrated into training datasets. Over 80% of LLM training data comes from web-scraped sources like Common Crawl. Anthropic used this dataset in some experiments.

[arxiv.org/html/2506.01732v1](arxiv.org/html/2506.01732v1)


**Investigating Implicit Bias in Large Language Models (2024)**

Large-scale study of 50+ LLMs finding that newer or larger models don't automatically reduce bias—in some cases they amplify it. Claude models showed "moderate to high levels of bias" with significant variation across versions.

[arxiv.org/html/2410.12864v1](arxiv.org/html/2410.12864v1)

### Projects Worth Supporting

| Title | Description | Link |
| ----- | ----------- | ---- |
| Standard Ebooks | Free, beautifully formatted public domain books | [standardebooks.org](https://standardebooks.org/) |
| Internet Archive | Preserving the web and providing free access to knowledge | [archive.org](https://archive.org/) |

**TODO:** Add more OSK-aligned projects. Investopedia as example of good execution? Farnam Street?

*Last update: 2026.02.04 (DRAFT)*